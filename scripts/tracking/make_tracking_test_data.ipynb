{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Training Data (Movies/Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is not currently used\n",
    "\n",
    "import os\n",
    "\n",
    "setlst = os.listdir('./')\n",
    "all_sets = []\n",
    "for term in setlst:\n",
    "    if 'set' in term:\n",
    "        all_sets.append(term)\n",
    "\n",
    "for set in all_sets:\n",
    "    temp = os.listdir(os.path.join('.', set, ))\n",
    "    direc_name = os.path.join('.', set, 'movie')\n",
    "    output_path = os.path.join('.', set, 'final')\n",
    "    partslst = []\n",
    "    if not 'annotations' in temp:\n",
    "        partslst = os.listdir(os.path.join('.', set))\n",
    "    print(partslst)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/mnt_madrox/Data/data/cells/3T3/NIH/set0/part_1/movie/02_00/raw'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-24398915c735>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mnum_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mreshape_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     verbose = True)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/deepcell/utils/data_utils.py\u001b[0m in \u001b[0;36mmake_training_data\u001b[0;34m(direc_name, file_name_save, channel_names, dimensionality, training_direcs, raw_image_direc, annotation_direc, annotation_name, reshape_size, **kwargs)\u001b[0m\n\u001b[1;32m    871\u001b[0m                               \u001b[0mreshape_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreshape_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                               \u001b[0mmontage_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'montage_mode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m                               num_frames=kwargs.get('num_frames', 50))\n\u001b[0m\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/deepcell/utils/data_utils.py\u001b[0m in \u001b[0;36mmake_training_data_3d\u001b[0;34m(direc_name, file_name_save, channel_names, training_direcs, annotation_name, raw_image_direc, annotation_direc, reshape_size, num_frames, montage_mode)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0mrand_train_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_train_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_train_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m     \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_train_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     X = load_training_images_3d(direc_name, training_direcs,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/deepcell/utils/io_utils.py\u001b[0m in \u001b[0;36mget_image_sizes\u001b[0;34m(data_location, channel_names)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mimg_list_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchannel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchannel_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mimg_list_channels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnikon_getfiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mimg_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_list_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/deepcell/utils/io_utils.py\u001b[0m in \u001b[0;36mnikon_getfiles\u001b[0;34m(direc_name, channel_name)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mchannel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \"\"\"\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mimglist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirec_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mimgfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimglist\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mchannel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mimgfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_nicely\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/mnt_madrox/Data/data/cells/3T3/NIH/set0/part_1/movie/02_00/raw'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "make_training_data_tracking.py - for multiple sets of data with multiple parts and montages\n",
    "\n",
    "Executing functions for creating npz files containing the training data\n",
    "Functions will create training data for either\n",
    "    - Patchwise sampling\n",
    "    - Fully convolutional training of single image conv-nets\n",
    "    - Fully convolutional training of movie conv-nets\n",
    "\n",
    "Files should be placed in training directories with each separate\n",
    "dataset getting its own folder\n",
    "\n",
    "@author: David Van Valen\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Import packages\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import pathlib\n",
    "import skimage as sk\n",
    "import scipy as sp\n",
    "from scipy import ndimage\n",
    "from skimage import feature\n",
    "from skimage import morphology as morph\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import class_weight\n",
    "from deepcell import get_image\n",
    "from deepcell import make_training_data\n",
    "# from deepcell import format_coord as cf\n",
    "\n",
    "# Load data\n",
    "#direc_name = '/data/data/cells/3T3/NIH/set2/part_2/movie'\n",
    "direc_name = '/data/mnt_madrox/Data/data/cells/3T3/NIH/set0/part_1/movie'\n",
    "output_directory = '/data/mnt_madrox/Data/npz_data/cells/3T3/NIH/movie'\n",
    "file_name_save = os.path.join( output_directory, 'nuclear_movie_3T3_S0P1_same.npz')\n",
    "# Training directories are organized according to location within an image\n",
    "num_x = 7 # Define num of horizontal samples\n",
    "num_y = 7 # Define num of vertical samples\n",
    "samples_to_drop = ['01_05','04_01','05_01','06_01','06_04'] # Some movies/montages/samples do not contain cells or contain annotation errors\n",
    "#samples_to_drop = []\n",
    "# Build list of possible training directories (excluding those to be dropped)\n",
    "training_direcs = ['0{}_0{}'.format(i,j) for i in range(num_x) for j in range(num_y)]\n",
    "training_direcs = [x for x in training_direcs if x not in samples_to_drop]\n",
    "channel_names = [\"\"] # Commonality in raw filenames\n",
    "\n",
    "# Create output ditrectory, if necessary\n",
    "pathlib.Path(output_directory).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create the training data\n",
    "make_training_data(\n",
    "    direc_name = direc_name,\n",
    "    file_name_save = file_name_save,\n",
    "    channel_names = channel_names,\n",
    "    dimensionality = 3,\n",
    "    training_direcs = training_direcs,\n",
    "    raw_image_direc = \"raw\",\n",
    "    annotation_direc = \"annotated\",\n",
    "    annotation_name = \"\",\n",
    "    border_mode = \"same\",\n",
    "    output_mode = \"conv\",\n",
    "    num_frames = 30,\n",
    "    reshape_size = None,\n",
    "    verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make_training_data_tracking.py - for a single directory of data\n",
    "\n",
    "Import packages\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import pathlib\n",
    "import skimage as sk\n",
    "import scipy as sp\n",
    "from scipy import ndimage\n",
    "from skimage import feature\n",
    "from skimage import morphology as morph\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import class_weight\n",
    "from deepcell import get_image\n",
    "from deepcell import make_training_data\n",
    "\n",
    "# Load data\n",
    "direc_name = '/data/data/cells/HeLa/S3/set0/HeLaTrackingTests'\n",
    "output_directory = '/data/data/cells/HeLa/S3/set0/HeLaTrackingTests/'\n",
    "file_name_save = os.path.join(output_directory, 'nuclear_movie_HeLa_set0_large.npz')\n",
    "# Build list of possible training directories (excluding those to be dropped)\n",
    "training_direcs = ['set0']\n",
    "channel_names = [\"\"] # Commonality in raw filenames\n",
    "\n",
    "# Create output ditrectory, if necessary\n",
    "pathlib.Path(output_directory).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create the training data\n",
    "make_training_data(\n",
    "    direc_name = direc_name,\n",
    "    file_name_save = file_name_save,\n",
    "    channel_names = channel_names,\n",
    "    dimensionality = 3,\n",
    "    training_direcs = training_direcs,\n",
    "    raw_image_direc = \"raw\",\n",
    "    annotation_direc = \"annotated\",\n",
    "    annotation_name = \"\",\n",
    "    output_mode = \"conv\",\n",
    "    num_frames = 30,\n",
    "    reshape_size = None,\n",
    "    verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to compile multiple sets together\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "base_path = '/data/npz_data/cells/3T3/NIH/movie/nuclear_movie_3T3_'\n",
    "num_of_sets = 5\n",
    "\n",
    "# Instantiate arrays to hold the final trading data and fill them\n",
    "X_full = np.empty((0, 30, 154, 182, 1))\n",
    "y_full = np.empty((0, 30, 154, 182, 1))\n",
    "for movie in range(num_of_sets):\n",
    "    path = os.path.join(base_path + str(movie) + '_same.npz')\n",
    "    data = np.load(path)\n",
    "    print(data.keys())\n",
    "    X_to_load, y_to_load = data['X'], data['y']\n",
    "    print('X Shape:', X_to_load.shape)\n",
    "    print('y Shape:', y_to_load.shape)\n",
    "    X_full = np.concatenate((X_full, X_to_load), axis=0)\n",
    "    y_full = np.concatenate((y_full, y_to_load), axis=0)\n",
    "    \n",
    "# Save the result to a new npz\n",
    "output_directory = '/data/npz_data/cells/3T3/NIH/movie/'\n",
    "file_name_save = os.path.join( output_directory, 'nuclear_movie_3T3_0-2_same.npz')\n",
    "\n",
    "np.savez(file_name_save, X=X_full, y=y_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'y']\n",
      "X Shape: (245, 30, 154, 182, 1)\n",
      "y Shape: (245, 30, 154, 182, 1)\n"
     ]
    }
   ],
   "source": [
    "# Verify the result\n",
    "data = np.load('/data/npz_data/cells/3T3/NIH/movie/nuclear_movie_3T3_0-2_same.npz')\n",
    "X_to_load, y_to_load = data['X'][()], data['y'][()]\n",
    "\n",
    "print(data.keys())\n",
    "data_readable_X, data_readable_y = data['X'][()], data['y'][()]\n",
    "print('X Shape:', data_readable_X.shape)\n",
    "print('y Shape:', data_readable_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'y']\n",
      "X Shape: (1, 45, 1080, 1280, 1)\n",
      "y Shape: (1, 45, 1080, 1280, 1)\n"
     ]
    }
   ],
   "source": [
    "# Verify the result\n",
    "data = np.load('/data/data/cells/HeLa/S3/set0/HeLaTrackingTests/nuclear_movie_HeLa_set0_large.npz')\n",
    "X_to_load, y_to_load = data['X'][()], data['y'][()]\n",
    "\n",
    "print(data.keys())\n",
    "data_readable_X, data_readable_y = data['X'][()], data['y'][()]\n",
    "print('X Shape:', data_readable_X.shape)\n",
    "print('y Shape:', data_readable_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Training Data (Division Information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "csv_path = '/data/npz_data/cells/HeLa/S3/movie/divisions-HeLa.csv'\n",
    "\n",
    "#Open .csv file containing hand-curated cell division data\n",
    "divisions_csv = pd.read_csv(csv_path)\n",
    "\n",
    "#Convert nan entries to blanks, i.e. ''\n",
    "divisions_csv = divisions_csv.replace(np.nan, 0, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Throw away all montages we decided not to use for training\n",
    "\n",
    "throw_away_indices = divisions_csv.loc[:, r'dont use (true)'] == True\n",
    "\n",
    "keep_indices = ~throw_away_indices\n",
    "\n",
    "divisions_csv = divisions_csv.loc[keep_indices,:]\n",
    "\n",
    "divisions_csv.head(6201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def division_per_montage(set_num, montage):\n",
    "    parents = []\n",
    "    daughters = []\n",
    "    for row in divisions_csv.itertuples():\n",
    "        if row.set == set_num and row.montage == montage and row.daughter != 0:\n",
    "            parents.append(row.label)\n",
    "            daughter_values = [int(x) for x in row.daughter.split(',')]\n",
    "            daughters.append(daughter_values)\n",
    "\n",
    "    npz_arr = []\n",
    "    for i in range(31):\n",
    "        npz_arr.append(np.array([]))\n",
    "    for idx, parent in enumerate(parents):\n",
    "        ind = int(parent)\n",
    "        npz_arr[ind] = np.array(daughters[idx])\n",
    "    \n",
    "    return npz_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_sets = 8\n",
    "\n",
    "# unique_montages contains a list of each montage grouped by set - index by unique_montages[set][montage = 00_0, 00_1]\n",
    "unique_montages = divisions_csv['montage'].groupby(divisions_csv['set']).unique()\n",
    "\n",
    "children = []\n",
    "for set_num in range(num_of_sets):\n",
    "    for montage in unique_montages[set_num]:\n",
    "        arr_to_append = division_per_montage(set_num, montage)\n",
    "        children.append(arr_to_append)\n",
    "        \n",
    "for batch in range(len(children)):\n",
    "    for i, lst in enumerate(children[batch]):\n",
    "        children[batch][i] = np.asarray(lst, dtype='int32')\n",
    "\n",
    "children = np.array(children)\n",
    "np.savez('/data/npz_data/cells/HeLa/S3/movie/nuclear_movie_hela0-7_same_kids.npz', daughters=children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets check against the original file for formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the original kids npz to see if it looks correct\n",
    "data = np.load('/data/npz_data/cells/HeLa/S3/movie/nuclear_movie_hela0-7_same_kids.npz')\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data from keys to deconsruct\n",
    "data_readable = data['daughters']\n",
    "data_readable.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first two entries for structure\n",
    "data_readable[0:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the original kids npz to see if it looks correct\n",
    "data = np.load('/data/npz_data/cells/HeLa/S3/movie/combined_daugthers.npz')\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data from keys to deconsruct\n",
    "data_readable = data['daughters']\n",
    "data_readable.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first two entries for structure\n",
    "data_readable[0:2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ending Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all montages \n",
    "movies = os.listdir(base_direc)\n",
    "movies.sort()\n",
    "\n",
    "\n",
    "\n",
    "children = []\n",
    "for movie in movies:\n",
    "    path = os.path.join(base_direc, movie, 'division.npz')\n",
    "    training_data = np.load(path)\n",
    "    children.append(training_data['arr_0'].tolist())\n",
    "\n",
    "for batch in range(len(children)):\n",
    "    for i, lst in enumerate(children[batch]):\n",
    "        children[batch][i] = np.asarray(lst, dtype=int32)\n",
    "\n",
    "children = np.array(children)\n",
    "#np.savez(os.path.join(output_path, 'combined_daugthers.npz'), daughters=children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(base_direc, output_path):\n",
    "    movies = os.listdir(base_direc)\n",
    "    movies.sort()\n",
    "    children = []\n",
    "    for movie in movies:\n",
    "        path = os.path.join(base_direc, movie, 'division.npz')\n",
    "        if os.path.isfile(path):\n",
    "            print(movie)\n",
    "            training_data = np.load(path)\n",
    "            children.append(training_data['arr_0'].tolist())\n",
    "\n",
    "    for batch in range(len(children)):\n",
    "        for i, lst in enumerate(children[batch]):\n",
    "            children[batch][i] = np.asarray(lst, dtype=int32)\n",
    "\n",
    "    children = np.array(children)\n",
    "    np.savez(os.path.join(output_path, 'combined_daugthers.npz'), daughters=children)\n",
    "    data = np.load(os.path.join(output_path, 'combined_daugthers.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "divisions_csv.loc[(divisions_csv['column_name'] != 0) & (divisions_csv['montage' == montage)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for row in divisions_csv.itertuples():\n",
    "    if row.daugter != 0:\n",
    "        count = count + 1\n",
    "#        print(divisions_csv['daugter'])\n",
    "#     print(divisions_csv['set'])   \n",
    "print('number of divisions:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/data/npz_data/cells/HeLa/S3/movie/nuclear_movie_HeLa_'\n",
    "num_of_sets = 8\n",
    "\n",
    "for movie in range(num_of_sets):\n",
    "    path = os.path.join(base_path + str(movie) + 'division.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setlst = os.listdir('./')\n",
    "all_sets = []\n",
    "for term in setlst:\n",
    "    if 'set' in term:\n",
    "        all_sets.append(term)\n",
    "\n",
    "for set in all_sets:\n",
    "    temp = os.listdir(os.path.join('.', set, ))\n",
    "    base_direc = os.path.join('.', set, 'movie')\n",
    "    output_path = os.path.join('.', set, 'final')\n",
    "    partslst = []\n",
    "    if not 'annotations' in temp:\n",
    "        partslst = os.listdir(os.path.join('.', set))\n",
    "    print(partslst)\n",
    "        if len(partslst) == 0:\n",
    "            print(base_direc, output_path)\n",
    "            combine(base_direc, output_path)\n",
    "        else:\n",
    "            for part in partslst:\n",
    "                base_direc = os.path.join('.', set, part, 'movie')\n",
    "                output_path = os.path.join('.', set, part, 'final')\n",
    "                combine(base_direc, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.empty([2, 31], dtype='int32')\n",
    "x = []\n",
    "\n",
    "# Make an empty array for a single montage\n",
    "npz_arr = []\n",
    "for i in range(31):\n",
    "    npz_arr.append([])\n",
    "\n",
    "# Put two blank montages together\n",
    "for i in range(2):\n",
    "    x.append(np.array(npz_arr, dtype='int32'))\n",
    "\n",
    "x = np.array(x)\n",
    "x.shape\n",
    "\n",
    "# Save it as an npz file\n",
    "# np.savez('/home/HeLa_output/set0_files/04_2/output.npz', npz_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build division npz for each montage (movie)\n",
    "set_num = 0\n",
    "# unique_montages contains a list of each montage grouped by set - index by unique_montages[set][montage = 00_0, 00_1]\n",
    "unique_montages = divisions_csv['montage'].groupby(divisions_csv['set']).unique()\n",
    "\n",
    "parents = []\n",
    "daughters = []\n",
    "for row in divisions_csv.itertuples():\n",
    "    if row.set == set_num and row.montage == '00_0' and row.daugter != 0:\n",
    "        parents.append(row.label)\n",
    "        daughter_values = [int(x) for x in row.daugter.split(',')]\n",
    "        daughters.append(daughter_values)\n",
    "\n",
    "npz_arr = []\n",
    "for i in range(31):\n",
    "    npz_arr.append(np.array([]))\n",
    "for idx, parent in enumerate(parents):\n",
    "    ind = int(parent)\n",
    "    npz_arr[ind] = np.array(daughters[idx])\n",
    "\n",
    "#np.savez(os.path.join(output_dir, 'division.npz'), npz_arr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
