{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watershed distance transform for 3-dimensional data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import errno\n",
    "import argparse\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.optimizers import SGD, Adam\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "\n",
    "from deepcell import get_data\n",
    "from deepcell import make_training_data\n",
    "from deepcell import rate_scheduler\n",
    "from deepcell.model_zoo import siamese_model\n",
    "from deepcell.training import train_model_siamese_daughter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv Based Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_OUTPUT_MODE = 'siamese_daughters' \n",
    "BORDER_MODE = 'same'\n",
    "RESIZE = False\n",
    "RESHAPE_SIZE = None\n",
    "NUM_FRAMES = 40  # get first N frames from each training folder\n",
    "\n",
    "# filepath constants\n",
    "DATA_DIR = '/data/data'\n",
    "MODEL_DIR = '/data/models'\n",
    "NPZ_DIR = '/data/npz_data'\n",
    "RESULTS_DIR = '/data/results'\n",
    "EXPORT_DIR = '/data/exports'\n",
    "PREFIX = 'cells/HeLa/S3'\n",
    "#CONV_DATA_FILE = 'nuclear_movie_HeLa_{}'.format(DATA_OUTPUT_MODE)\n",
    "\n",
    "direc_name = '/data/data/cells/HeLa/S3/set1/movie'\n",
    "direc_data = '/data/npz_data/cells/HeLa/S3/movie/'\n",
    "output_directory = '/data/npz_data/cells/HeLa/S3/set1/movie1/'\n",
    "file_name_save = os.path.join( output_directory, 'nuclear_movie_HeLa_1_same.npz')\n",
    "\n",
    "# Training directories are organized according to location within an image\n",
    "num_x = 5 # Define num of horizontal samples\n",
    "num_y = 5 # Define num of vertical samples\n",
    "samples_to_drop = ['01_0'] # Some samples do not contain cells\n",
    "# Build list of possible training directories (excluding those to be dropped)\n",
    "training_direcs = ['0{}_{}'.format(i,j) for i in range(num_x) for j in range(num_y)]\n",
    "training_direcs = [x for x in training_direcs if x not in samples_to_drop]\n",
    "channel_names = [\"slice\"]\n",
    "\n",
    "# Create output ditrectory, if necessary\n",
    "#pathlib.Path( output_directory ).mkdir( parents=True, exist_ok=True )\n",
    "\n",
    "# The following is left from Wills tests and may be useful:\n",
    "# Check for channels_first or channels_last\n",
    "#IS_CHANNELS_FIRST = K.image_data_format() == 'channels_first'\n",
    "\n",
    "#ROW_AXIS = 3 if IS_CHANNELS_FIRST else 2\n",
    "#COL_AXIS = 4 if IS_CHANNELS_FIRST else 3\n",
    "#CHANNEL_AXIS = 1 if IS_CHANNELS_FIRST else 4\n",
    "\n",
    "# create these directories if they do not exist\n",
    "#for d in (NPZ_DIR, MODEL_DIR, RESULTS_DIR):\n",
    "#    try:\n",
    "#        os.makedirs(os.path.join(d, PREFIX))\n",
    "#        print('Created new directory:', os.path.join(d, PREFIX))\n",
    "#    except OSError as exc:  # Guard against race condition\n",
    "#        if exc.errno != errno.EEXIST:\n",
    "#            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training data\n",
    "make_training_data(window_size_x = 30, window_size_y = 30,\n",
    "    direc_name = direc_name,\n",
    "    montage_mode=False,\n",
    "    file_name_save = file_name_save,\n",
    "    training_direcs = training_direcs,\n",
    "    channel_names = channel_names,\n",
    "    dimensionality = 3,\n",
    "    annotation_name = \"\",\n",
    "    raw_image_direc = \"processed\",\n",
    "    annotation_direc = \"annotated\",\n",
    "    border_mode = \"same\",\n",
    "    output_mode = \"conv\",\n",
    "    num_frames = 40,\n",
    "    reshape_size = None,\n",
    "    display = False,\n",
    "    num_of_frames_to_display = 5,\n",
    "    verbose = True)\n",
    "\n",
    "# The following is left from Wills tests and may be useful:\n",
    "#make_training_data(\n",
    "#    dimensionality=3,\n",
    "#    direc_name=os.path.join(DATA_DIR, PREFIX),\n",
    "#    file_name_save=os.path.join(NPZ_DIR, PREFIX, CONV_DATA_FILE),\n",
    "#    channel_names=['slice'],  # for iterating over stacks of images from a montage\n",
    "#    training_direcs=['set6'],\n",
    "#    output_mode=DATA_OUTPUT_MODE,\n",
    "#    window_size_x=30,\n",
    "#    window_size_y=30,\n",
    "#    window_size_z=3,\n",
    "#    border_mode=BORDER_MODE,\n",
    "#    reshape_size=None if not RESIZE else RESHAPE_SIZE,\n",
    "#    process=True,\n",
    "#    process_std=True,\n",
    "#    display=False,\n",
    "#    num_frames=NUM_FRAMES,\n",
    "#    num_of_frames_to_display=5,\n",
    "#    verbose=True,\n",
    "#    montage_mode=True,  # annotation folder has montaged sub-dirs\n",
    "#    annotation_name='',  # basically channel name but for annotated images\n",
    "#    raw_image_direc='stacked_raw',\n",
    "#    annotation_direc='annotated/all_montages')\n",
    "\n",
    "#if os.path.isfile(os.path.join(NPZ_DIR, PREFIX, CONV_DATA_FILE) + '.npz'):\n",
    "#    print('\\nData saved to', os.path.join(NPZ_DIR, PREFIX, CONV_DATA_FILE) + '.npz')\n",
    "#else:\n",
    "#    raise Exception('Your data file did not save properly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data from NPZ into a numpy array\n",
    "#training_data = np.load(os.path.join(NPZ_DIR, PREFIX, CONV_DATA_FILE + '.npz'))\n",
    "training_data = np.load('{}{}.npz'.format(direc_data, dataset))\n",
    "\n",
    "X, y = training_data['X'], training_data['y']\n",
    "print('X.shape: {}\\ny.shape: {}'.format(X.shape, y.shape))\n",
    "\n",
    "in_shape = (32, 32, 1)\n",
    "\n",
    "# Set up training parameters\n",
    "n_epoch = 10\n",
    "batch_size = 128\n",
    "#frames_per_batch = 10\n",
    "optimizer = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "lr_sched = rate_scheduler(lr=0.001, decay=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create the Siamese model\n",
    "\n",
    "# Instantiate the model\n",
    "comparator_model = siamese_model(input_shape=in_shape)\n",
    "\n",
    "# Train the model\n",
    "train_model_siamese_daughter(\n",
    "    model=comparator_model,\n",
    "    dataset=dataset,\n",
    "    optimizer=optimizer,\n",
    "    expt='',\n",
    "    it=0,\n",
    "    batch_size=batch_size,\n",
    "    n_epoch=n_epoch,\n",
    "    direc_save='/data/models/cells/HeLa/S3',\n",
    "#   direc_save=os.path.join(MODEL_DIR, PREFIX),\n",
    "#   direc_data=os.path.join(NPZ_DIR, PREFIX),\n",
    "    direc_data=direc_data,\n",
    "    lr_sched=lr_sched,\n",
    "#   class_weight=training_data['class_weights'],\n",
    "    rotation_range=0,\n",
    "    flip=True,\n",
    "    shear=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start here with a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this is your starting point, you will need some housekeeping\n",
    "from deepcell.model_zoo import siamese_model\n",
    "from deepcell import get_data\n",
    "\n",
    "direc_data = '/data/npz_data/cells/HeLa/S3/movie/'\n",
    "dataset = 'nuclear_movie_hela0-3_same'\n",
    "MODEL_DIR = '/data/models'\n",
    "PREFIX = 'cells/HeLa/S3'\n",
    "\n",
    "in_shape = (32, 32, 1)\n",
    "\n",
    "# Now we can load some data to test on \n",
    "# For this example we load some data that we could train on:\n",
    "training_data_file = '{}{}.npz'.format(direc_data, dataset)\n",
    "train_dict, val_dict = get_data(training_data_file, mode='siamese_daughters')\n",
    "\n",
    "# We need to set a few parameters for the following functions\n",
    "data_format = K.image_data_format()\n",
    "\n",
    "if data_format == 'channels_first':\n",
    "    channel_axis = 1\n",
    "    row_axis = 3\n",
    "    col_axis = 4\n",
    "    time_axis = 2\n",
    "if data_format == 'channels_last':\n",
    "    channel_axis = 4\n",
    "    row_axis = 2\n",
    "    col_axis = 3\n",
    "    time_axis = 1\n",
    "x = np.asarray(train_dict['X'], dtype=K.floatx())\n",
    "y = np.array(train_dict['y'], dtype='int32')\n",
    "\n",
    "# Now we need to re-instantiate the model and load weights\n",
    "siamese_weights_file = '2018-08-13_nuclear_movie_hela0-3_same__0.h5'\n",
    "siamese_weights_file = os.path.join(MODEL_DIR, PREFIX, siamese_weights_file)\n",
    "\n",
    "comparator_model = siamese_model(input_shape=in_shape)\n",
    "comparator_model.load_weights(siamese_weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (86, 40, 216, 256, 1)\n",
      "y shape (86, 40, 216, 256, 1)\n",
      "Movie shape (40, 216, 256, 1)\n",
      "Annotation shape (40, 216, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create our first movie and annotation to test the tracker\n",
    "print('X shape', x.shape)\n",
    "print('y shape', y.shape)\n",
    "\n",
    "first_movie = np.zeros(x[0].shape)\n",
    "first_annotation = np.zeros(y[0].shape)\n",
    "\n",
    "print('Movie shape', first_movie.shape)\n",
    "print('Annotation shape', first_annotation.shape)\n",
    "\n",
    "first_movie = x[0]\n",
    "first_annotation = y[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Tracking Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.tracking import cell_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "test_tracker = cell_tracker(\n",
    "    movie = first_movie, \n",
    "    annotation = first_annotation, \n",
    "    model = comparator_model, \n",
    "    crop_dim=32, \n",
    "    death=0.5, \n",
    "    birth=0.75,\n",
    "    max_distance=200,\n",
    "    track_length=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify Annotation Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels before:  [0 1 2 3 4]\n",
      "Labels after:   [0 1 2 3 4]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imshow\n",
    "\n",
    "test_tracker._clean_up_annotations()\n",
    "\n",
    "# Compare labels in existence\n",
    "unique_cells_before = np.unique(first_annotation[0])\n",
    "unique_cells_after = np.unique(test_tracker.y[0])\n",
    "print('Labels before: ',unique_cells_before)\n",
    "print('Labels after:  ',unique_cells_after)\n",
    "\n",
    "# Compare 2 images\n",
    "before = first_annotation[0,:,:,0]\n",
    "after = test_tracker.y[0,:,:,0]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,12))\n",
    "ax[0].imshow(before, interpolation='none', cmap='gray')\n",
    "ax[1].imshow(after, interpolation='none', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Cost Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9986004  0.999298   0.00501609 0.01515502]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "first_frame = 0\n",
    "first_cost_matrix = test_tracker._get_cost_matrix(frame = first_frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Assignment Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "._track_cells()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "index = 0\n",
    "frame = 8\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, nrows=2, figsize=(15, 15), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(X_test[index, frame, :, :, 0])\n",
    "ax[0].set_title('Source Image')\n",
    "\n",
    "ax[1].imshow(test_images_fgbg[index, frame, :, :, 1])\n",
    "ax[1].set_title('Segmentation Prediction')\n",
    "\n",
    "ax[2].imshow(fg_thresh[index, frame, :, :, 0], cmap='jet')\n",
    "ax[2].set_title('Thresholded Segmentation')\n",
    "\n",
    "ax[3].imshow(argmax_images[index, frame, :, :, 0], cmap='jet')\n",
    "ax[3].set_title('Watershed Transform')\n",
    "\n",
    "ax[4].imshow(argmax_images_post_fgbg[index, frame, :, :, 0], cmap='jet')\n",
    "ax[4].set_title('Watershed Transform w/o Background')\n",
    "\n",
    "ax[5].imshow(watershed_images[index, frame, :, :, 0], cmap='jet')\n",
    "ax[5].set_title('Watershed Segmentation')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "def get_js_video(images, batch=0, channel=0):\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    ims = []\n",
    "    for i in range(images.shape[1]):\n",
    "        im = plt.imshow(images[batch, i, :, :, channel], animated=True, cmap='jet')\n",
    "        ims.append([im])\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=150, repeat_delay=1000)\n",
    "    return HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_js_video(argmax_images_post_fgbg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_js_video(watershed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
