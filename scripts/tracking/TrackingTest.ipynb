{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import errno\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.optimizers import SGD, Adam\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "\n",
    "from deepcell import get_data\n",
    "from deepcell import make_training_data\n",
    "from deepcell import rate_scheduler\n",
    "from deepcell.model_zoo import siamese_model\n",
    "from deepcell.training import train_model_siamese_daughter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from deepcell import rate_scheduler\n",
    "from deepcell.model_zoo import siamese_model\n",
    "from deepcell.training import train_model_siamese_daughter\n",
    "\n",
    "direc_data = '/data/npz_data/cells/HeLa/S3/movie/'\n",
    "dataset = 'nuclear_movie_hela0-7_same'\n",
    "\n",
    "#direc_data = '/data/npz_data/cells/3T3/NIH/'\n",
    "#dataset = 'nuclear_movie_3t3_set1_same'\n",
    "\n",
    "training_data = np.load('{}{}.npz'.format(direc_data, dataset))\n",
    "\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "lr_sched = rate_scheduler(lr=0.001, decay=0.99)\n",
    "in_shape = (32, 32, 1)\n",
    "features = {\"appearance\", \"distance\", \"neighborhood\", \"perimeter\"}\n",
    "\n",
    "model = siamese_model(input_shape=in_shape, features=features)\n",
    "\n",
    "tracking_model = train_model_siamese_daughter(model=model,\n",
    "                                              dataset=dataset,\n",
    "                                              optimizer=optimizer,\n",
    "                                              expt='transform_sync',\n",
    "                                              it=0,\n",
    "                                              batch_size=128,\n",
    "                                              min_track_length=6,\n",
    "                                              features=features,\n",
    "                                              n_epoch=5,\n",
    "                                              direc_save='/data/models/cells/HeLa/S3',\n",
    "                                              direc_data=direc_data,\n",
    "                                              lr_sched=lr_sched,\n",
    "                                              rotation_range=180,\n",
    "                                              flip=True,\n",
    "                                              shear=0,\n",
    "                                              class_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/data/npz_data/cells/HeLa/S3/movie/nuclear_movie_hela0-7_same.npz')\n",
    "#data = np.load('/data/npz_data/cells/HeLa/S3/movie/nuclear_movie_HeLa_0_same.npz')\n",
    "data.keys()\n",
    "data_readable_X, data_readable_y = data['X'][()], data['y'][()]\n",
    "print('X Shape:', data_readable_X.shape)\n",
    "print('y Shape:', data_readable_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imshow\n",
    "\n",
    "img_raw = data_readable_X[0,0,:,:,0]\n",
    "img_ann = data_readable_y[0,0,:,:,0]\n",
    "\n",
    "# Visualize the result \n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,12))\n",
    "ax[0].imshow(img_raw, interpolation='none', cmap='gray')\n",
    "ax[1].imshow(img_ann, interpolation='none', cmap='gray')\n",
    "ax[0].set_title('Contrast (or Raw) Images')\n",
    "ax[1].set_title('Annotated Images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict, val_dict = get_data('/data/npz_data/cells/HeLa/S3/movie/nuclear_movie_hela0-7_same.npz',\n",
    "                                        mode='siamese_daughters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imshow\n",
    "\n",
    "# Compare 2 images\n",
    "img_1 = train_dict['X'][0,1,:,:,0]\n",
    "img_2 = train_dict['y'][0,1,:,:,0]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,12))\n",
    "ax[0].imshow(img_1, interpolation='none', cmap='gray')\n",
    "ax[1].imshow(img_2, interpolation='none', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tracking function\n",
    "from deepcell.tracking import cell_tracker\n",
    "\n",
    "# Load up data to test\n",
    "train_dict, val_dict = get_data('/data/npz_data/cells/HeLa/S3/movie/nuclear_movie_hela0-7_same.npz',\n",
    "                                        mode='siamese_daughters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.model_zoo import siamese_model\n",
    "\n",
    "# Import the tracking model\n",
    "MODEL_DIR = '/data/models'\n",
    "PREFIX = 'cells/HeLa/S3'\n",
    "in_shape = (32, 32, 1)\n",
    "features = {\"perimeter\", \"appearance\", \"neighborhood\", \"distance\"}\n",
    "\n",
    "# Now we need to re-instantiate the model and load weights\n",
    "siamese_weights_file = '2018-10-10_nuclear_movie_hela0-7_same_[a,d,n,p]_n_epoch=5_transform_sync_1.h5'\n",
    "siamese_weights_file = os.path.join(MODEL_DIR, PREFIX, siamese_weights_file)\n",
    "\n",
    "tracking_model = siamese_model(input_shape=in_shape, features=features)\n",
    "tracking_model.load_weights(siamese_weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch = 2\n",
    "\n",
    "trial = cell_tracker(train_dict['X'][batch], train_dict['y'][batch],\n",
    "                     tracking_model,\n",
    "                     max_distance=1000,\n",
    "                     track_length=5, division=0.5, birth=0.9, death=0.9,\n",
    "                     features=features)\n",
    "trial._track_cells()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "def get_js_video(images, batch=0, channel=0):\n",
    "    fig = plt.figure()    \n",
    "    ims = []\n",
    "    for i in range(images.shape[1]):\n",
    "        im = plt.imshow(images[batch, i, :, :, channel], animated=True, cmap='jet', vmin=0, vmax=15)\n",
    "        ims.append([im])\n",
    "        ani = animation.ArtistAnimation(fig, ims, interval=75, repeat_delay=1000)\n",
    "    return HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_js_video(train_dict['y'], batch=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_js_video(np.expand_dims(trial.y_tracked, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Raw and Tracked Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 0\n",
    "\n",
    "for i in range(40):\n",
    "    name_raw = os.path.join('test_raw_' + str(i) + '_.png')\n",
    "    name_tracked = os.path.join('test_tracked_' + str(i) + '_.png')\n",
    "    plt.imsave(name_raw, train_dict['X'][batch, i, :, :, channel], cmap='gray')\n",
    "    plt.imsave(name_tracked, trial.y_tracked[i, :, :, channel], cmap='jet', vmin=0, vmax=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trial.y_tracked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print([trial.tracks[key]['parent'] for key in trial.tracks.keys()])\n",
    "print([trial.tracks[key]['daughters'] for key in trial.tracks.keys()])\n",
    "print([trial.tracks[key]['label'] for key in trial.tracks.keys()])\n",
    "print([trial.tracks[key]['capped'] for key in trial.tracks.keys()])\n",
    "print([key for key in trial.tracks.keys()])\n",
    "print(trial.tracks[6]['frames'])\n",
    "print(trial.tracks[8]['frames'])\n",
    "print(trial.tracks[9]['frames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "datagen_val = SiameseDataGenerator(\n",
    "    rotation_range=180,  # randomly rotate images by 0 to rotation_range degrees\n",
    "    shear_range=0,  # randomly shear images in the range (radians , -shear_range to shear_range)\n",
    "    horizontal_flip=0,  # randomly flip images\n",
    "    vertical_flip=0)  # randomly flip images\n",
    "\n",
    "batch_size=128\n",
    "min_track_length=5\n",
    "# fit the model on the batches generated by datagen.flow()\n",
    "test = datagen_val.flow(train_dict, batch_size=batch_size, min_track_length=min_track_length, shuffle=False)\n",
    "\n",
    "cm = np.zeros((3,3))\n",
    "N_div = 0.\n",
    "N_tot = 0.\n",
    "\n",
    "for batch_x, batch_y in test:\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    y_pred = tracking_model.predict(batch_x)\n",
    "    \n",
    "    truth = np.argmax(batch_y, axis=-1)\n",
    "    pred = np.argmax(y_pred, axis=-1)\n",
    "    cm_temp = confusion_matrix(truth,pred)\n",
    "    if cm_temp.shape[0] == 2:\n",
    "        cm[0:2,0:2] += cm_temp\n",
    "    else:\n",
    "        cm += confusion_matrix(truth,pred)\n",
    "        \n",
    "    N_div += np.sum(truth == 2)\n",
    "    N_tot += truth.shape[0]\n",
    "    \n",
    "    print(np.round(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2), N_div/N_tot)\n",
    "\n",
    "    \n",
    "# y_true = test.classes\n",
    "# y_pred = tracking_model.predict_generator(test)\n",
    "# print(y_pred)\n",
    "# Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "# y_pred = model.predict_classes(x_test)\n",
    "# print(classification_report(y_true, np.argmax(y_pred, axis=-1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
