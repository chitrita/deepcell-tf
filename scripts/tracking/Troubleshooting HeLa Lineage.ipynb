{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_name, mode='sample', test_size=.1, seed=None):\n",
    "    \"\"\"Load data from NPZ file and split into train and test sets\n",
    "    # Arguments\n",
    "        file_name: path to NPZ file to load\n",
    "        mode: if 'sample', will return datapoints for each pixel,\n",
    "              otherwise, returns the same data that was loaded\n",
    "        test_size: percent of data to leave as testing holdout\n",
    "        seed: seed number for random train/test split repeatability\n",
    "    # Returns\n",
    "        dict of training data, and a tuple of testing data:\n",
    "        train_dict, (X_test, y_test)\n",
    "    \"\"\"\n",
    "    training_data = np.load(file_name)\n",
    "    X = training_data['X']\n",
    "    y = training_data['y']\n",
    "    win_x = training_data['win_x']\n",
    "    win_y = training_data['win_y']\n",
    "    win_z = None\n",
    "\n",
    "    class_weights = training_data['class_weights'] if 'class_weights' in training_data else None\n",
    "\n",
    "    if mode == 'sample' and X.ndim == 4:\n",
    "        batch = training_data['batch']\n",
    "        pixels_x = training_data['pixels_x']\n",
    "        pixels_y = training_data['pixels_y']\n",
    "\n",
    "        if CHANNELS_FIRST:\n",
    "            sample_shape = (len(batch), X.shape[1], 2 * win_x + 1, 2 * win_y + 1)\n",
    "        else:\n",
    "            sample_shape = (len(batch), 2 * win_x + 1, 2 * win_y + 1, X.shape[3])\n",
    "        X_sample = np.zeros(sample_shape, dtype=K.floatx())\n",
    "\n",
    "        for i, (b, px, py) in enumerate(zip(batch, pixels_x, pixels_y)):\n",
    "            if CHANNELS_FIRST:\n",
    "                X_sample[i] = X[b, :, px - win_x:px + win_x + 1, py - win_y:py + win_y + 1]\n",
    "            else:\n",
    "                X_sample[i] = X[b, px - win_x:px + win_x + 1, py - win_y:py + win_y + 1, :]\n",
    "\n",
    "        X = X_sample\n",
    "\n",
    "\n",
    "    # siamese_data mode creates additional channels for tracking data (centroid x, centroid y, etc)\n",
    "    if mode == 'siamese_data':\n",
    "        batch_length = X.shape[0]\n",
    "\n",
    "        if CHANNELS_FIRST:\n",
    "            X_new = np.zeros((X.shape[0], X.shape[1]+2, X.shape[2], X.shape[3], X.shape[4]))\n",
    "            x_centroid_weight_dist = np.zeros(X.shape[3], X.shape[4])\n",
    "            y_centroid_weight_dist = np.zeros(X.shape[3], X.shape[4])\n",
    "            num_frames = X.shape[2]\n",
    "        else:\n",
    "            X_new = np.zeros((X.shape[0], X.shape[1], X.shape[2], X.shape[3], X.shape[4]+2))\n",
    "            x_centroid_weight_dist = np.zeros((X.shape[2], X.shape[3]))\n",
    "            y_centroid_weight_dist = np.zeros((X.shape[2], X.shape[3]))\n",
    "            num_frames = X.shape[1]\n",
    "\n",
    "        for b in range(batch_length):\n",
    "            for f in range(num_frames):\n",
    "                if CHANNELS_FIRST:\n",
    "                    X_new[b,1,f,:,:] = X[b,0,f,:,:]\n",
    "                    X_new[b,1,f,:,:], X_new[b,2,f,:,:] = centroid_weighted_distance_transform_2d(y[b,0,f,:,:])\n",
    "                else:\n",
    "                    X_new[b,f,:,:,0] = X[b,f,:,:,0]\n",
    "                    X_new[b,f,:,:,1], X_new[b,f,:,:,2] = centroid_weighted_distance_transform_2d(y[b,f,:,:,0])\n",
    "\n",
    "        X = X_new\n",
    "    # End changes for data mode\n",
    "\n",
    "    elif mode == 'sample' and X.ndim == 5:\n",
    "        batch = training_data['batch']\n",
    "        pixels_x = training_data['pixels_x']\n",
    "        pixels_y = training_data['pixels_y']\n",
    "        pixels_z = training_data['pixels_z']\n",
    "        win_z = training_data['win_z']\n",
    "\n",
    "        if CHANNELS_FIRST:\n",
    "            sample_shape = (len(batch), X.shape[1], 2 * win_z + 1, 2 * win_x + 1, 2 * win_y + 1)\n",
    "        else:\n",
    "            sample_shape = (len(batch), 2 * win_z + 1, 2 * win_x + 1, 2 * win_y + 1, X.shape[4])\n",
    "        X_sample = np.zeros(sample_shape, dtype=K.floatx())\n",
    "\n",
    "        for i, (b, px, py, pz) in enumerate(zip(batch, pixels_x, pixels_y, pixels_z)):\n",
    "            if CHANNELS_FIRST:\n",
    "                X_sample[i] = X[b, :, pz - win_z:pz + win_z + 1, px - win_x:px + win_x + 1, py - win_y:py + win_y + 1]\n",
    "            else:\n",
    "                X_sample[i] = X[b, pz - win_z:pz + win_z + 1, px - win_x:px + win_x + 1, py - win_y:py + win_y + 1, :]\n",
    "\n",
    "        X = X_sample\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=seed)\n",
    "\n",
    "    train_dict = {\n",
    "        'X': X_train,\n",
    "        'y': y_train,\n",
    "        'class_weights': class_weights,\n",
    "        'win_x': win_x,\n",
    "        'win_y': win_y\n",
    "    }\n",
    "\n",
    "    # siamese_daughters mode is used to import lineage data and associate it with the appropriate batch\n",
    "    if mode == 'siamese_daughters':\n",
    "        kid_data = np.load(os.path.splitext(file_name)[0]+'_kids.npz')\n",
    "        daughters = kid_data['daughters']\n",
    "        X_train, X_test, y_train, y_test, lineage_train, lineage_test = train_test_split(X, y, daughters, test_size=test_size, random_state=seed)\n",
    "        train_dict = {\n",
    "            'X': X_train,\n",
    "            'y': y_train,\n",
    "            'daughters': lineage_train,\n",
    "            'class_weights': class_weights,\n",
    "            'win_x': win_x,\n",
    "            'win_y': win_y\n",
    "        }\n",
    "        y_test = [y_test, lineage_test]\n",
    "    # End changes for daughter mode\n",
    "\n",
    "    if win_z is not None:\n",
    "        train_dict['win_z'] = win_z\n",
    "\n",
    "\n",
    "    return train_dict, (X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.image import Iterator\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "class SiameseDataGenerator(ImageDataGenerator):\n",
    "    def flow(self,\n",
    "             train_dict,\n",
    "             crop_dim=32,\n",
    "             min_track_length=5,\n",
    "             batch_size=32,\n",
    "             shuffle=True,\n",
    "             seed=None,\n",
    "             data_format=None,\n",
    "             save_to_dir=None,\n",
    "             save_prefix='',\n",
    "             save_format='png'):\n",
    "        return SiameseIterator(\n",
    "            train_dict,\n",
    "            self,\n",
    "            crop_dim=crop_dim,\n",
    "            min_track_length=min_track_length,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            seed=seed,\n",
    "            data_format=data_format,\n",
    "            save_to_dir=save_to_dir,\n",
    "            save_prefix=save_prefix,\n",
    "            save_format=save_format)\n",
    "\n",
    "\n",
    "class SiameseIterator(Iterator):\n",
    "    def __init__(self,\n",
    "                 train_dict,\n",
    "                 image_data_generator,\n",
    "                 crop_dim=14,\n",
    "                 min_track_length=5,\n",
    "                 batch_size=32,\n",
    "                 shuffle=False,\n",
    "                 seed=None,\n",
    "                 data_format=None,\n",
    "                 save_to_dir=None,\n",
    "                 save_prefix='',\n",
    "                 save_format='png'):\n",
    "        if data_format is None:\n",
    "            data_format = K.image_data_format()\n",
    "\n",
    "        if data_format == 'channels_first':\n",
    "            self.channel_axis = 1\n",
    "            self.row_axis = 3\n",
    "            self.col_axis = 4\n",
    "            self.time_axis = 2\n",
    "        if data_format == 'channels_last':\n",
    "            self.channel_axis = 4\n",
    "            self.row_axis = 2\n",
    "            self.col_axis = 3\n",
    "            self.time_axis = 1\n",
    "        self.x = np.asarray(train_dict['X'], dtype=K.floatx())\n",
    "        self.y = np.array(train_dict['y'], dtype='int32')\n",
    "\n",
    "        if self.x.ndim != 5:\n",
    "            raise ValueError('Input data in `SiameseIterator` '\n",
    "                             'should have rank 5. You passed an array '\n",
    "                             'with shape', self.x.shape)\n",
    "\n",
    "        self.crop_dim = crop_dim\n",
    "        self.min_track_length = min_track_length\n",
    "        self.image_data_generator = image_data_generator\n",
    "        self.data_format = data_format\n",
    "        self.save_to_dir = save_to_dir\n",
    "        self.save_prefix = save_prefix\n",
    "        self.save_format = save_format\n",
    "\n",
    "        if 'daughters' in train_dict:\n",
    "            self.daughters = train_dict['daughters']\n",
    "        else:\n",
    "            self.daughters = None\n",
    "\n",
    "        self.track_ids = self._get_track_ids()\n",
    "\n",
    "        super(SiameseIterator, self).__init__(\n",
    "            len(self.track_ids), batch_size, shuffle, seed)\n",
    "\n",
    "    def _get_track_ids(self):\n",
    "        \"\"\"\n",
    "        This function builds the track id's. It returns a dictionary that\n",
    "        contains the batch number and label number of each each track.\n",
    "        Creates unique cell IDs, as cell labels are NOT unique across batches.\n",
    "        \"\"\"\n",
    "        track_counter = 0\n",
    "        track_ids = {}\n",
    "        for batch in range(self.y.shape[0]):\n",
    "            y_batch = self.y[batch]\n",
    "            num_cells = np.amax(y_batch)\n",
    "            for cell in range(1, num_cells + 1):\n",
    "                # count number of pixels cell occupies in each frame\n",
    "                y_true = np.sum(y_batch == cell, axis=(self.row_axis - 1, self.col_axis - 1))\n",
    "                # get indices of frames where cell is present\n",
    "                y_index = np.where(y_true > 0)[0]\n",
    "                if y_index.size > 0:  # if cell is present at all\n",
    "                    #start_frame = np.amin(y_index)\n",
    "                    #stop_frame = np.amax(y_index)\n",
    "                    if self.daughters is not None:\n",
    "                        track_ids[track_counter] = {\n",
    "                            'batch': batch,\n",
    "                            'label': cell,\n",
    "                            'frames': y_index,\n",
    "                            'daughters': self.daughters[batch][cell]  # not [cell-1]!\n",
    "                        }\n",
    "                    else:\n",
    "                        track_ids[track_counter] = {\n",
    "                            'batch': batch,\n",
    "                            'label': cell,\n",
    "                            'frames': y_index,\n",
    "                            'daughters': []\n",
    "                        }\n",
    "                    track_counter += 1\n",
    "        return track_ids\n",
    "\n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        # initialize batch_x_1, batch_x_2, and batch_y, as well as centroid data\n",
    "        if self.data_format == 'channels_first':\n",
    "            img_shape = (len(index_array), self.x.shape[self.channel_axis], self.crop_dim, self.crop_dim)\n",
    "        else:\n",
    "            img_shape = (len(index_array), self.crop_dim, self.crop_dim, self.x.shape[self.channel_axis])\n",
    "\n",
    "        data_shape = (len(index_array), 2,)\n",
    "\n",
    "        batch_x_1 = np.zeros(img_shape, dtype=K.floatx())\n",
    "        batch_x_2 = np.zeros(img_shape, dtype=K.floatx())\n",
    "        centroid_1 = np.zeros(data_shape, dtype=K.floatx())\n",
    "        centroid_2 = np.zeros(data_shape, dtype=K.floatx())\n",
    "        batch_y = np.zeros((len(index_array), 3), dtype=np.int32)\n",
    "\n",
    "        for i, j in enumerate(index_array):\n",
    "            # Identify which tracks are going to be selected\n",
    "            track_id = self.track_ids[j]\n",
    "            batch = track_id['batch']\n",
    "            label_1 = track_id['label']\n",
    "            tracked_frames = track_id['frames']\n",
    "            frame_1 = np.random.choice(tracked_frames)  # Select a frame from the track\n",
    "\n",
    "            X = self.x[batch]\n",
    "            y = self.y[batch]\n",
    "\n",
    "            # Choose comparison cell\n",
    "            # Determine what class the track will be - different (0), same (1), division (2)\n",
    "            # is_same_cell = np.random.random_integers(0, 1)\n",
    "            type_cell = np.random.randint(0, 3)\n",
    "\n",
    "            # There may be instances where training images only have one cell\n",
    "            # In this case, we won't be able to find a diff cell to compare to\n",
    "            # So we begin by compiling a list of valid cell labels (ie: all\n",
    "            # cell labels except the first chosen label)\n",
    "            all_labels = np.delete(np.unique(y), 0)  # all labels in y but 0 (background)\n",
    "            acceptable_labels = np.delete(all_labels, np.where(all_labels == label_1))\n",
    "\n",
    "            # If there is only 1 cell in every frame, we can only choose the class to be same\n",
    "            if len(acceptable_labels) == 0:\n",
    "                type_cell = 1\n",
    "\n",
    "            # If class is division, check if the first cell divides\n",
    "            # If not, change class to same/dif randomly\n",
    "            if type_cell == 2:\n",
    "                daughters = track_id['daughters']\n",
    "                if len(daughters) == 0:\n",
    "                    type_cell = np.random.random_integers(0, 1)  # No children so randomly choose a diff class\n",
    "                else:\n",
    "                    frame_1 = np.amax(tracked_frames)  # Get the last frame of the parent\n",
    "                    frame_2 = frame_1 + 1\n",
    "                    # There should always be 2 daughters but not always a valid label\n",
    "                    label_2 = int(daughters[np.random.random_integers(0, len(daughters)-1)])\n",
    "\n",
    "            # If class is same, select another frame from the same track\n",
    "            if type_cell == 1:\n",
    "                label_2 = label_1\n",
    "                # The second frame should not be equal to the first (an exact comparison)\n",
    "                # We need to assemble a new list of valid frames\n",
    "                tracked_frames = np.delete(tracked_frames, np.where(tracked_frames == frame_1))\n",
    "                # And verify the cell exists in more than one frame (otherwise cell it can't be tracked)\n",
    "                if len(tracked_frames) > 0:\n",
    "                    frame_2 = np.random.choice(tracked_frames)\n",
    "                else:\n",
    "                    # The cell only appears in one frame so it either split in frame 2 or it can't \n",
    "                    # (doesn't need to) be tracked. Either way, we need to select randomly from one of\n",
    "                    # the other classes (different or daughter)\n",
    "                    type_cell = np.random.randint(0, 2) * 2\n",
    "                    if type_cell == 2:\n",
    "                        daughters = track_id['daughters']\n",
    "                        if len(daughters) == 0:\n",
    "                            type_cell = 0 # No children & only appears in 1 frame, class must be different\n",
    "                        else:\n",
    "                            frame_1 = np.amax(tracked_frames)  # Get the last frame of the parent\n",
    "                            frame_2 = frame_1 + 1\n",
    "                            # There should always be 2 daughters but not always a valid label\n",
    "                            label_2 = int(daughters[np.random.random_integers(0, len(daughters)-1)])\n",
    "                    # A failure mode could be that we assumed that the class must be same because there's only\n",
    "                    #  one label present but now we're enforcing class = different (which is a contradiction. \n",
    "                    if type_cell == 0 and len(acceptable_labels) == 0:\n",
    "                        raise ValueError('Invalid input data. There is only one labeled cell and it only '\n",
    "                                         'exists in one frame. This type of data is unsuitable for tracking'\n",
    "                                         'Batch #{} and Label {}'.format(batch, label_1))\n",
    "\n",
    "            # If class is different, select another frame from a different track\n",
    "            if type_cell == 0:\n",
    "                   \n",
    "                is_valid_label = False\n",
    "                while not is_valid_label:\n",
    "                    # get a random cell label from our acceptable list\n",
    "                    label_2 = np.random.choice(acceptable_labels)\n",
    "\n",
    "                    # count number of pixels cell occupies in each frame\n",
    "                    y_true = np.sum(y == label_2, axis=(\n",
    "                        self.row_axis - 1, self.col_axis - 1, self.channel_axis - 1))\n",
    "\n",
    "                    y_index = np.where(y_true > 0)[0]  # get frames where cell is present\n",
    "                    is_valid_label = y_index.any()  # label_2 is in a frame\n",
    "                    if not is_valid_label:\n",
    "                        # remove invalid label from list of acceptable labels\n",
    "                        acceptable_labels = np.delete(\n",
    "                            acceptable_labels, np.where(acceptable_labels == label_2))\n",
    "\n",
    "                frame_2 = np.random.choice(y_index)  # get random frame with label_2\n",
    "\n",
    "            # Get appearances and centroid data\n",
    "            frames = [frame_1, frame_2]\n",
    "            labels = [label_1, label_2]\n",
    "\n",
    "            appearances = self._get_appearances(X, y, frames, labels)\n",
    "\n",
    "            # Save centroids for the pair of images\n",
    "            centroid_1[i] = np.array(appearances[1][0])\n",
    "            centroid_2[i] = np.array(appearances[1][1])\n",
    "\n",
    "            # Save images of the cells in the pair of images\n",
    "            appearances = appearances[0]\n",
    "\n",
    "            if self.data_format == 'channels_first':\n",
    "                appearances = [appearances[:, 0], appearances[:, 1]]\n",
    "            else:\n",
    "                appearances = [appearances[0], appearances[1]]\n",
    "\n",
    "            # Apply random transformations\n",
    "            for k, appearance in enumerate(appearances):\n",
    "                appearance = self.image_data_generator.random_transform(appearance)\n",
    "                appearance = self.image_data_generator.standardize(appearance)\n",
    "                appearances[k] = appearance\n",
    "\n",
    "            batch_x_1[i] = appearances[0]\n",
    "            batch_x_2[i] = appearances[1]\n",
    "            batch_y[i, type_cell] = 1\n",
    "\n",
    "        return [batch_x_1, batch_x_2, centroid_1, centroid_2], batch_y\n",
    "\n",
    "    def _get_appearances(self, X, y, frames, labels):\n",
    "        channel_axis = self.channel_axis - 1\n",
    "        if self.data_format == 'channels_first':\n",
    "            appearance_shape = (X.shape[channel_axis],\n",
    "                                len(frames),\n",
    "                                self.crop_dim,\n",
    "                                self.crop_dim)\n",
    "        else:\n",
    "            appearance_shape = (len(frames),\n",
    "                                self.crop_dim,\n",
    "                                self.crop_dim,\n",
    "                                X.shape[channel_axis])\n",
    "\n",
    "        # Initialize storage for appearances and centroids\n",
    "        appearances = np.zeros(appearance_shape, dtype=K.floatx())\n",
    "        centroids = []\n",
    "\n",
    "        for counter, (frame, cell_label) in enumerate(zip(frames, labels)):\n",
    "            # Get the bounding box\n",
    "            y_frame = y[frame] if self.data_format == 'channels_last' else y[:, frame]\n",
    "            props = regionprops(np.int32(y_frame == cell_label))\n",
    "            minr, minc, maxr, maxc = props[0].bbox\n",
    "            centroids.append(props[0].centroid)\n",
    "\n",
    "            # Extract images from bounding boxes\n",
    "            if self.data_format == 'channels_first':\n",
    "                appearance = X[:, frame, minr:maxr, minc:maxc]\n",
    "                resize_shape = (X.shape[channel_axis], self.crop_dim, self.crop_dim)\n",
    "            else:\n",
    "                appearance = X[frame, minr:maxr, minc:maxc, :]\n",
    "                resize_shape = (self.crop_dim, self.crop_dim, X.shape[channel_axis])\n",
    "\n",
    "            # Resize images from bounding box\n",
    "            max_value = np.amax([np.amax(appearance), np.absolute(np.amin(appearance))])\n",
    "            appearance /= max_value\n",
    "            appearance = resize(appearance, resize_shape)\n",
    "            appearance *= max_value\n",
    "            if self.data_format == 'channels_first':\n",
    "                appearances[:, counter] = appearance\n",
    "            else:\n",
    "                appearances[counter] = appearance\n",
    "\n",
    "        return [appearances, centroids]\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns the next batch.\n",
    "        \"\"\"\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array = next(self.index_generator)\n",
    "        # The transformation of images is not under thread lock\n",
    "        # so it can be done in parallel\n",
    "        return self._get_batches_of_transformed_samples(index_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/data/npz_data/cells/HeLa/S3/set2/movie1/nuclear_movie_HeLa2_raw_same.npz')\n",
    "train_dict, (X_test, y_test) = get_data('/data/npz_data/cells/HeLa/S3/set2/movie1/nuclear_movie_HeLa2_raw_same.npz',\n",
    "                                        mode='siamese_data')\n",
    "\n",
    "print('X_train shape:', train_dict['X'].shape)\n",
    "\n",
    "image_data_generator = SiameseDataGenerator(\n",
    "        rotation_range=0,  # randomly rotate images by 0 to rotation_range degrees\n",
    "        shear_range=0, # randomly shear images in the range (radians , -shear_range to shear_range)\n",
    "        horizontal_flip=0,  # randomly flip images\n",
    "        vertical_flip=0) \n",
    "\n",
    "test_iterator = SiameseIterator(train_dict, image_data_generator, crop_dim=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imshow\n",
    "\n",
    "# Compare 2 images\n",
    "img_1 = train_dict['X'][0,1,:,:,0]\n",
    "img_2 = train_dict['X'][0,1,:,:,0]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,12))\n",
    "ax[0].imshow(img_1, interpolation='none', cmap='gray')\n",
    "ax[1].imshow(img_2, interpolation='none', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lst, y) = test_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = lst[0][1,:,:,0]\n",
    "img_2 = lst[1][1,:,:,0]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,12))\n",
    "ax[0].imshow(img_1, interpolation='none', cmap='gray')\n",
    "ax[1].imshow(img_2, interpolation='none', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Centroid Data\n",
    "print(np.amax(lst[0][1,:,:,1]))\n",
    "print(np.amax(lst[1][1,:,:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the labels\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.activations import softmax\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Conv2D, Conv3D, ConvLSTM2D\n",
    "from tensorflow.python.keras.layers import Add, Input, Concatenate, Lambda\n",
    "from tensorflow.python.keras.layers import MaxPool2D, MaxPool3D, AvgPool2D, UpSampling2D\n",
    "from tensorflow.python.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.python.keras.layers import Activation, Softmax\n",
    "from tensorflow.python.keras.layers import BatchNormalization\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "\n",
    "from .layers import Resize\n",
    "from .layers import DilatedMaxPool2D, DilatedMaxPool3D\n",
    "from .layers import TensorProd2D, TensorProd3D\n",
    "from .layers import Location, Location3D\n",
    "from .layers import ImageNormalization2D, ImageNormalization3D\n",
    "\n",
    "def siamese_model(input_shape=None, batch_shape=None, reg=1e-5, init='he_normal', softmax=True, norm_method='std', filter_size=61):\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    # Define the input shape for the images\n",
    "    input_1 = Input(shape=input_shape)\n",
    "    input_2 = Input(shape=input_shape)\n",
    "    # Define the input shape for the other data (centroids, etc)\n",
    "    input_3 = Input(shape=(2, ))\n",
    "    input_4 = Input(shape=(2, ))\n",
    "\n",
    "    # Sequential interface for siamese portion of model\n",
    "    feature_extractor = Sequential()\n",
    "    feature_extractor.add(Conv2D(64, (3, 3), kernel_initializer=init, padding='same', kernel_regularizer=l2(reg), input_shape=input_shape))\n",
    "    feature_extractor.add(BatchNormalization(axis=channel_axis))\n",
    "    feature_extractor.add(Activation('relu'))\n",
    "    feature_extractor.add(Conv2D(64, (3, 3), kernel_initializer=init, padding='same', kernel_regularizer=l2(reg)))\n",
    "    feature_extractor.add(BatchNormalization(axis=channel_axis))\n",
    "    feature_extractor.add(Activation('relu'))\n",
    "    feature_extractor.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    feature_extractor.add(Conv2D(64, (3, 3), kernel_initializer=init, padding='same', kernel_regularizer=l2(reg)))\n",
    "    feature_extractor.add(BatchNormalization(axis=channel_axis))\n",
    "    feature_extractor.add(Activation('relu'))\n",
    "    feature_extractor.add(Conv2D(64, (3, 3), kernel_initializer=init, padding='same', kernel_regularizer=l2(reg)))\n",
    "    feature_extractor.add(BatchNormalization(axis=channel_axis))\n",
    "    feature_extractor.add(Activation('relu'))\n",
    "    feature_extractor.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Create two instances of feature_extractor\n",
    "    output_1 = feature_extractor(input_1)\n",
    "    output_2 = feature_extractor(input_2)\n",
    "\n",
    "    # Combine the extracted features with other known features (centroids)\n",
    "    flat1 = Flatten()(output_1)\n",
    "    flat2 = Flatten()(output_2)\n",
    "    merge_1 = Concatenate()([flat1, input_3])\n",
    "    merge_2 = Concatenate()([flat2, input_4])\n",
    "\n",
    "    # Concatenate outputs from both instances\n",
    "    merged_outputs = Concatenate(axis=channel_axis)([merge_1, merge_2])\n",
    "\n",
    "    # Implement dense net (Alternatively, could call preexisting) with the 2 merged outputs as inputs\n",
    "    dense1 = Dense(128)(merged_outputs)\n",
    "    bn1 = BatchNormalization(axis=channel_axis)(dense1)\n",
    "    relu1 = Activation('relu')(bn1)\n",
    "    dense2 = Dense(128)(relu1)\n",
    "    bn2 = BatchNormalization(axis=channel_axis)(dense2)\n",
    "    relu2 = Activation('relu')(bn2)\n",
    "    dense3 = Dense(3, activation='softmax')(relu2)\n",
    "\n",
    "    # Instantiate model\n",
    "    final_layer = dense3\n",
    "    model = Model(inputs=[input_1, input_2, input_3, input_4], outputs=final_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.external import tifffile as tiff\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.utils import to_categorical as keras_to_categorical\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "from .image_generators import SiameseDataGenerator\n",
    "from .losses import weighted_categorical_crossentropy\n",
    "from .utils.io_utils import get_images_from_directory\n",
    "from .utils.train_utils import rate_scheduler\n",
    "from .utils.transform_utils import to_categorical\n",
    "from .settings import CHANNELS_FIRST\n",
    "\n",
    "def train_model_siamese_daughter(model=None, dataset=None, optimizer=None,\n",
    "                        expt='', it=0, batch_size=1, n_epoch=100,\n",
    "                        direc_save='/data/models', direc_data='/data/npz_data',\n",
    "                        lr_sched=rate_scheduler(lr=0.01, decay=0.95),\n",
    "                        rotation_range=0, flip=True, shear=0, class_weight=None):\n",
    "\n",
    "    training_data_file_name = os.path.join(direc_data, dataset + '.npz')\n",
    "    todays_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    file_name_save = os.path.join(direc_save, '{}_{}_{}_{}.h5'.format(todays_date, dataset, expt, it))\n",
    "    file_name_save_loss = os.path.join(direc_save, '{}_{}_{}_{}.npz'.format(todays_date, dataset, expt, it))\n",
    "\n",
    "    train_dict, (X_test, y_test) = get_data(training_data_file_name, mode='siamese_daughters')\n",
    "\n",
    "    class_weights = train_dict['class_weights']\n",
    "    # the data, shuffled and split between train and test sets\n",
    "    print('X_train shape:', train_dict['X'].shape)\n",
    "    print('y_train shape:', train_dict['y'].shape)\n",
    "    print('X_test shape:', X_test.shape)\n",
    "    print('y_test shape:', y_test[0].shape)\n",
    "    print('Output Shape:', model.layers[-1].output_shape)\n",
    "\n",
    "    n_classes = model.layers[-1].output_shape[1 if CHANNELS_FIRST else -1]\n",
    "\n",
    "    def loss_function(y_true, y_pred):\n",
    "        return weighted_categorical_crossentropy(y_true, y_pred,\n",
    "                                                 n_classes=n_classes,\n",
    "                                                 from_logits=False)\n",
    "\n",
    "    model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    print('Using real-time data augmentation.')\n",
    "\n",
    "    # this will do preprocessing and realtime data augmentation\n",
    "    datagen = SiameseDataGenerator(\n",
    "        rotation_range=rotation_range,  # randomly rotate images by 0 to rotation_range degrees\n",
    "        shear_range=shear,  # randomly shear images in the range (radians , -shear_range to shear_range)\n",
    "        horizontal_flip=flip,  # randomly flip images\n",
    "        vertical_flip=flip)  # randomly flip images\n",
    "\n",
    "    datagen_val = SiameseDataGenerator(\n",
    "        rotation_range=0,  # randomly rotate images by 0 to rotation_range degrees\n",
    "        shear_range=0,  # randomly shear images in the range (radians , -shear_range to shear_range)\n",
    "        horizontal_flip=0,  # randomly flip images\n",
    "        vertical_flip=0)  # randomly flip images\n",
    "\n",
    "    validation_dict = {'X': X_test, 'y': y_test[0], 'daughters': y_test[1]}\n",
    "\n",
    "    def count_pairs(y):\n",
    "        \"\"\"\n",
    "        Compute number of training samples needed to (stastically speaking)\n",
    "        observe all cell pairs.\n",
    "        Assume that the number of images is encoded in the second dimension.\n",
    "        Assume that y values are a cell-uniquely-labeled mask.\n",
    "        Assume that a cell is paired with one of its other frames 50% of the time\n",
    "        and a frame from another cell 50% of the time.\n",
    "        \"\"\"\n",
    "        # TODO: channels_first axes\n",
    "        total_pairs = 0\n",
    "        for image_set in range(y.shape[0]):\n",
    "            set_cells = 0\n",
    "            cells_per_image = []\n",
    "            for image in range(y.shape[1]):\n",
    "                image_cells = int(y[image_set, image, :, :, :].max())\n",
    "                set_cells = set_cells + image_cells\n",
    "                cells_per_image.append(image_cells)\n",
    "\n",
    "            # Since there are many more possible non-self pairings than there are self pairings,\n",
    "            # we want to estimate the number of possible non-self pairings and then multiply\n",
    "            # that number by two, since the odds of getting a non-self pairing are 50%, to\n",
    "            # find out how many pairs we would need to sample to (statistically speaking)\n",
    "            # observe all possible cell-frame pairs.\n",
    "            # We're going to assume that the average cell is present in every frame. This will\n",
    "            # lead to an underestimate of the number of possible non-self pairings, but it's\n",
    "            # unclear how significant the underestimate is.\n",
    "            average_cells_per_frame = int(sum(cells_per_image) / len(cells_per_image))\n",
    "            non_self_cellframes = (average_cells_per_frame - 1) * len(cells_per_image)\n",
    "            non_self_pairings = non_self_cellframes * max(cells_per_image)\n",
    "            cell_pairings = non_self_pairings * 2\n",
    "            total_pairs = total_pairs + cell_pairings\n",
    "        return total_pairs\n",
    "\n",
    "    # This shouldn't remain long term.\n",
    "    total_train_pairs = count_pairs(train_dict['y'])\n",
    "    total_test_pairs = count_pairs(y_test[0])\n",
    "\n",
    "    print(\"total_train_pairs:\", total_train_pairs)\n",
    "    print(\"total_test_pairs:\", total_test_pairs)\n",
    "    print(\"batch size: \", batch_size)\n",
    "    print(\"validation_steps: \", total_test_pairs // batch_size)\n",
    "\n",
    "    # fit the model on the batches generated by datagen.flow()\n",
    "    loss_history = model.fit_generator(\n",
    "        datagen.flow(train_dict, batch_size=batch_size),\n",
    "        steps_per_epoch=total_train_pairs // batch_size,\n",
    "        epochs=n_epoch,\n",
    "        validation_data=datagen_val.flow(validation_dict, batch_size=batch_size),\n",
    "        validation_steps=total_test_pairs // batch_size,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(file_name_save, monitor='val_loss', verbose=1, save_best_only=True, mode='auto'),\n",
    "            LearningRateScheduler(lr_sched)\n",
    "        ])\n",
    "\n",
    "    model.save_weights(file_name_save)\n",
    "    np.savez(file_name_save_loss, loss_history=loss_history.history)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.optimizers import SGD\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "\n",
    "from deepcell import rate_scheduler, siamese_model, train_model_siamese_daughter\n",
    "\n",
    "direc_data = '/data/npz_data/cells/HeLa/S3/movie/'\n",
    "dataset = 'nuclear_movie_hela0_same'\n",
    "\n",
    "training_data = np.load('{}{}.npz'.format(direc_data, dataset))\n",
    "\n",
    "optimizer = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "lr_sched = rate_scheduler(lr=0.001, decay=0.99)\n",
    "in_shape = (32, 32, 1)\n",
    "model = siamese_model(input_shape=in_shape)\n",
    "for layer in model.layers:\n",
    "    print(layer.name)\n",
    "\n",
    "train_model_siamese_daughter(model=model,\n",
    "                    dataset=dataset,\n",
    "                    optimizer=optimizer,\n",
    "                    expt='',\n",
    "                    it=0,\n",
    "                    batch_size=128,\n",
    "                    n_epoch=10,\n",
    "                    direc_save='/data/models/cells/HeLa/S3',\n",
    "                    direc_data=direc_data,\n",
    "                    lr_sched=lr_sched,\n",
    "                    rotation_range=0,\n",
    "                    flip=True,\n",
    "                    shear=0,\n",
    "                    class_weight=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
